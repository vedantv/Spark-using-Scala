#String splitting to columns using regex

import org.apache.spark.sql.functions._
var dfr = spark.read.format("csv").option("header","true").load("/FileStore/tables/string_col.csv")
val l = dfr.select($"String_col").as[String].collect  //"123, ABCD, ^~Vedant, Vasishtha^~, ^~Shradha, Sharma^~"
val pattern = "\\^~[^\\^~~\\^]+~\\^".r
val ele = l(0).split("\\^~[^\\^~~\\^]+~\\^|,").map(_.trim).toList
val ele1 = ele.filter(_.length!=0)
//ele.foreach(println)
var matches = pattern.findAllIn(l(0)).toList
matches = matches.map(_.replaceAll("\\^~|~\\^", ""))
val m1 = ele1 ++ matches
var z = m1.toSeq
z.foreach(println)
a.foreach(println)
val dfrm = Seq((m1(0),m1(1),m1(2),m1(3),m1(4))).toDF("col1","col2","col3","col4","col5")
dfrm.show